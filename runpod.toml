[project]
name = "qwen-image-serverless"
version = "1.0.0"
description = "RunPod serverless function for Qwen-Image model"

[build]
base_image = "nvidia/cuda:11.8-devel-ubuntu22.04"
python_version = "3.10"
cuda_version = "11.8"

[runtime]
handler = "handler.py"
max_concurrency = 1
max_retries = 3
timeout_seconds = 300

[resources]
gpu_types = ["NVIDIA_RTX_A6000", "NVIDIA_A100", "NVIDIA_RTX_4090"]
min_vcpu = 4
min_memory = 16
min_disk = 50

[environment]
HF_HOME = "/runpod-volume/.cache/huggingface"
TRANSFORMERS_CACHE = "/runpod-volume/.cache/huggingface/transformers"
HF_DATASETS_CACHE = "/runpod-volume/.cache/huggingface/datasets"
CUDA_VISIBLE_DEVICES = "0"
PYTHONUNBUFFERED = "1"

[network]
ports = []

[scaling]
min_workers = 0
max_workers = 10
scale_up_threshold = 0.8
scale_down_threshold = 0.2
idle_timeout = 300